Ethical Decision-Making in IT
Lecture 9-10 - PPIT Fall 21

================================================================================
WHY THIS MATTERS
================================================================================

Technology creates new dilemmas every day:
- AI ethics and bias
- Privacy concerns
- Cybersecurity challenges
- Workplace surveillance
- Data collection and use
- Algorithmic decision-making

Key Challenges:
- Laws and regulations often lag behind technology
- Many issues are shades of grey, not simply right or wrong
- Unstructured decisions lead to bias, inconsistency, and reputational damage

Why Structured Ethical Decision-Making is Essential:
- Ensures decisions are principled (rooted in ethics, not just convenience)
- Makes decisions defensible (can be explained and justified)
- Ensures consistency (applicable across similar cases)
- Prevents harm to people and organizations
- Provides clear accountability and reasoning

================================================================================
WHY STRUCTURED ETHICAL DECISION-MAKING?
================================================================================

Problems with Unstructured Decisions:
-------------------------------------
1. Emotional Bias
   - Ignoring facts or acting on impulse
   - Making decisions based on feelings rather than analysis
   - Favoring immediate gratification over long-term consequences

2. Inconsistency
   - Similar cases handled differently
   - Lack of clear principles to guide decisions
   - Unfair treatment of stakeholders

3. Harm to People
   - Loss of trust
   - Privacy violations
   - Unfair treatment
   - Discrimination
   - Safety risks

4. Organizational Damage
   - Low employee morale
   - Loss of customers
   - Lawsuits and legal consequences
   - Reputational crises
   - Financial losses

5. Missed Accountability
   - No clear reasoning to defend the choice
   - Difficulty explaining decisions to stakeholders
   - Lack of documentation for future reference

Benefits of Structured Decision-Making:
--------------------------------------
- Ensures careful examination of facts
- Applies principles consistently
- Balances interests of multiple stakeholders
- Builds defensible, transparent outcomes
- Provides clear documentation
- Enables learning from past decisions

[Image: Comparison diagram showing unstructured vs. structured decision-making processes, highlighting the chaos of unstructured approaches versus the systematic nature of structured frameworks]

================================================================================
VALUE JUDGMENT IN ETHICAL DECISIONS
================================================================================

Every ethical dilemma requires a judgment about values:
- Whose interests matter most?
- Which rights or duties take precedence?
- What is "good" or "just" in this situation?
- How do we balance competing values?

Without judgment, decisions risk being:
- Random (no clear reasoning)
- Legalistic (only following rules without considering ethics)
- Emotional (based on feelings alone)

Value Judgment Defined:
-----------------------
- Balancing personal values with those of others
- Considering multiple perspectives
- Weighing competing principles
- Making principled, defensible choices

Goal: A principled, defensible choice that can be explained and justified to stakeholders.

[Image: Diagram showing the intersection of personal values, professional values, organizational values, and societal values in ethical decision-making]

================================================================================
FACTORS INFLUENCING OUR BEHAVIOR
================================================================================

Multiple layers influence human behavior:

1. Biological Needs
   - Drives for food, shelter, safety, love
   - Basic survival instincts
   - Physical and psychological needs
   - Example: Need for security may conflict with need for innovation

2. Social Influences
   - Rules and expectations
   - Culture and traditions
   - Religion and beliefs
   - Family values
   - Government regulations
   - Peer pressure
   - Example: Cultural norms about privacy vs. transparency

3. Moral/Ethical Understanding
   - What we believe is good, right, and just
   - Personal moral code
   - Professional ethics
   - Philosophical frameworks
   - Example: Belief in fairness vs. efficiency

Behavior = Outcome of all these layers interacting

Ethical dilemmas often arise when these influences conflict:
- Personal values vs. organizational values
- Short-term needs vs. long-term principles
- Individual rights vs. collective good
- Legal requirements vs. ethical obligations

[Image: Multi-layered model showing biological needs at the base, social influences in the middle, and moral/ethical understanding at the top, with arrows showing interactions between layers]

================================================================================
MASLOW'S HIERARCHY OF NEEDS
================================================================================

A classic psychological framework from Abraham Maslow (1943)

The hierarchy (from bottom to top):

1. Physiological Needs (Base Level)
   - Breathing, food, water, shelter, clothing, sleep
   - Basic survival requirements
   - Must be satisfied before higher needs become important
   - Example: A hungry person prioritizes food over self-actualization

2. Safety Needs
   - Health, employment, property, family and social stability
   - Security and protection from harm
   - Confidence in avoiding pain, hunger, and dangers
   - Example: Job security, financial stability, safe working environment

3. Social Needs (Love and Belonging)
   - Friendship, family, intimacy, sense of connection
   - Need to be part of a trusted group
   - Avoiding rejection or alienation
   - Example: Team membership, professional networks, community involvement

4. Self-Esteem Needs
   - Confidence, achievement, respect of others
   - Need to be a unique individual
   - Feeling admired and respected
   - Example: Professional recognition, career advancement, personal accomplishments

5. Self-Actualization (Highest Level)
   - Morality, creativity, spontaneity, acceptance
   - Experience purpose, meaning, and inner potential
   - Becoming the most complete and authentic version of oneself
   - Example: Pursuing ethical excellence, creative problem-solving, fulfilling professional purpose

Key Principles:
- Lower needs must be satisfied before higher needs become motivating
- Once a need is satisfied, it no longer motivates behavior
- People may have needs at multiple levels simultaneously
- Individual differences exist in how needs are prioritized

Relevance to Ethical Decision-Making:
- Understanding what motivates people helps predict behavior
- Ethical dilemmas may arise when needs conflict
- Professional ethics often relate to self-actualization level
- Organizational culture affects which needs are prioritized

[Image: Pyramid diagram showing Maslow's hierarchy with five levels, from Physiological at the base to Self-Actualization at the top, with examples of each level]

================================================================================
APPROACHES TO ETHICAL DECISION-MAKING
================================================================================

Three Main Approaches:

1. LAW AND ETHICS
-----------------
Start by asking if the law or regulations provide a clear answer.

Key Questions/Tests:
- Does the law address this situation?
- Do I need professional/legal advice?
- What are the legal requirements?
- What are the legal consequences?

Examples in IT Context:
- GDPR and data privacy: Is data collection compliant with law?
- Export control laws on encryption software
- Copyright and intellectual property laws
- Employment law and workplace surveillance
- Cybersecurity regulations

Limitations:
- Law may not address new technologies
- Legal compliance ≠ ethical behavior
- Laws vary by jurisdiction
- Laws may be outdated or unjust

2. INFORMAL GUIDELINES (QUICK TESTS)
-------------------------------------
Simple, personal checks that act as a first filter for ethical choices.
Useful when decisions need to be made quickly.

The Tests:

a) Secrecy Test
   - Is anyone asking me to keep this quiet?
   - Would I be comfortable if this were public?
   - If it needs to be secret, why?

b) Mom Test (Family Test)
   - Would I be proud to tell my mother/family?
   - Would I want my children to know about this?
   - Does this reflect my values?

c) TV Test (Publicity Test)
   - Would I be comfortable if this appeared on the news?
   - How would this look in a newspaper headline?
   - Would I be embarrassed if this became public?

d) Market Test
   - Could this behavior be advertised as a selling point?
   - Would customers want to know about this?
   - Would this enhance our reputation?

e) Smell Test (Intuition Test)
   - Does something feel "off" or wrong instinctively?
   - Am I trying to rationalize something I know is wrong?
   - Does this violate my gut feeling about right and wrong?

Examples in IT Context:
- Developer pressured to hide bugs in software before release (Secrecy Test)
- Sharing user data with advertisers without clear consent (TV Test)
- Launching an AI tool that may reinforce bias (Smell Test)
- Using customer data for purposes not disclosed (Mom Test)
- Implementing surveillance without transparency (Market Test)

3. FORMAL GUIDELINES (EXPLICIT STANDARDS)
------------------------------------------
Clear, written standards set by organizations or professions.
Provide consistency and accountability.

Key Questions:
- Does this violate corporate policy?
- Does it align with ACM/IEEE Code of Ethics?
- Does it follow professional standards?
- Does it comply with industry best practices?

The Golden Rule:
- Would I accept this if roles were reversed?
- How would I feel if this were done to me?
- Is this fair from all perspectives?

Examples in IT Context:
- Corporate IT security policy forbidding password sharing
- IEEE principle: avoid harm to others
- Would I want to receive spam if I were the user? (Golden Rule)
- ACM code: respect privacy and confidentiality
- Professional licensing requirements

[Image: Table comparing the three approaches: Law and Ethics, Informal Guidelines, and Formal Guidelines, showing when each is most appropriate]

================================================================================
ETHICAL DECISION-MAKING MODELS
================================================================================

Various models exist for structured ethical decision-making:

1. 4-STEP MODEL (1996)
-----------------------
Key Steps:
1. Recognize the issue
2. Define the dilemma
3. Evaluate alternatives
4. Decide & act (+ Reflect)

Focus: Simple, structured framework
Typical Use: Widely used in IT/business ethics
Strengths: Easy to remember and apply
Weaknesses: May oversimplify complex situations

2. REST'S FOUR-COMPONENT MODEL (1986)
-------------------------------------
Key Steps:
1. Moral awareness (recognizing ethical issue)
2. Moral judgment (evaluating what's right)
3. Moral intention (deciding to act ethically)
4. Moral action (actually doing what's right)

Focus: Explains why people act ethically
Typical Use: Strong in psychology & moral development
Strengths: Addresses the gap between knowing and doing
Weaknesses: More descriptive than prescriptive

3. PLUS MODEL
-------------
P = Policies (organizational policies)
L = Legal (legal requirements)
U = Universal principles (ethical principles)
S = Self test (personal values)

Focus: Business & corporate ethics
Typical Use: Used in compliance training
Strengths: Comprehensive checklist approach
Weaknesses: May not resolve conflicts between elements

4. NASH'S 12 QUESTIONS
----------------------
Reflection questions covering:
- Facts and alternatives
- Who's affected
- Reversibility (would I want this done to me?)
- Publicity (would I want this public?)
- Long-term consequences

Focus: Business ethics
Typical Use: Encourages deep reflection before acting
Strengths: Thorough analysis
Weaknesses: Time-consuming

5. TUCKER'S 5 QUESTIONS
------------------------
1. Is it Profitable?
2. Is it Legal?
3. Is it Fair?
4. Is it Right?
5. Is it Sustainable?

Focus: Managerial decision-making
Typical Use: Balancing profit and ethics
Strengths: Quick, practical framework
Weaknesses: May prioritize profit over ethics

6. KITCHENER'S PRINCIPLES
--------------------------
Five principles:
- Autonomy (respect for self-determination)
- Beneficence (doing good)
- Non-maleficence (avoiding harm)
- Justice (fairness)
- Fidelity (keeping promises)

Focus: Counseling/healthcare
Typical Use: Applicable broadly to respect and fairness
Strengths: Well-established principles
Weaknesses: Principles may conflict

7. MULTIDIMENSIONAL ETHICS SCALE (MES)
--------------------------------------
Evaluates across multiple perspectives:
- Moral equity
- Relativism
- Contractualism
- Egoism
- Utilitarianism

Focus: Research/academic model
Typical Use: Helps assess ethics across multiple perspectives
Strengths: Comprehensive analysis
Weaknesses: Complex, may be too academic for practical use

8. SOCIAL CONSTRUCTIVISM
------------------------
Key Elements:
- Consensus-building
- Dialogue
- Cultural context
- Relationships

Focus: Emphasizes stakeholder dialogue and cultural norms
Typical Use: Decision-making in diverse, multicultural contexts
Strengths: Inclusive, culturally sensitive
Weaknesses: May be slow, may not reach consensus

[Image: Comparison table of all ethical decision-making models, showing key steps, focus, and typical use cases]

================================================================================
4-STEP DECISION-MAKING FRAMEWORK
================================================================================

This is the primary framework we will use for ethical decision-making.

The Four Steps:
---------------
Step I. Understanding the situation
Step II. Isolating the major ethical dilemma
Step III. Analyzing the ethicality of both alternatives in Step II
Step IV. Making a decision and planning the implementation

[Image: Flowchart showing the 4-step process with arrows connecting each step]

================================================================================
CASE STUDY: AMAZON AI HIRING TOOL
================================================================================

Background:
-----------
Amazon needed to solve a hiring problem. A group of engineers was tasked with building a cutting-edge AI hiring tool. The pitch was bold: let algorithms scan résumés, score applicants, and present only the "best" to recruiters. Faster, cheaper, smarter hiring.

Initial Success:
---------------
At first, the system dazzled:
- It crunched data at lightning speed
- Ranking candidates in neat lists
- Managers called it "a revolution for HR"

Discovery of Bias:
-----------------
Deep inside the test results, one engineer, Alex, noticed something disturbing:
- The tool consistently downgraded résumés from women
- Graduates of women's colleges were scored lower
- Candidates who listed achievements in "women's chess clubs" or "women's soccer teams" were quietly pushed down the ranking

Root Cause:
----------
Alex dug deeper. The culprit was the data:
- The model had been trained on ten years of Amazon's own hiring history
- A history dominated by male engineers
- The AI had learned the wrong lesson: male = hireable, female = not a fit

The Dilemma:
-----------
Alex hesitated. Should he bring this up?

In a meeting with his manager, Alex voiced his concerns. The reaction was complicated:
- "Yes, there are issues, but the tool is saving us incredible time. We'll fix it later."
- "This bias is embarrassing, but if we stop now, we'll miss our deadlines. Leadership won't be happy."

The Pressure:
-------------
- Deliver a working system or risk being seen as the roadblock
- Rolling out the tool in its current form meant baking discrimination into Amazon's future hiring decisions
- Talented women would be quietly sidelined by a machine that mirrored society's flaws

Alex's Decision Point:
---------------------
Alone at his desk that evening, Alex stared at the résumés on his screen — talented women quietly sidelined by a machine that mirrored society's flaws. Alex now faces a dilemma: tomorrow he has to decide.

[Image: Visual representation of the Amazon case study showing the AI system, biased data, and the ethical dilemma]

================================================================================
STEP I: UNDERSTANDING THE SITUATION
================================================================================

A. List and number the relevant facts.
   - It should be a neutral and logical exercise
   - Do not judge the facts at this stage
   - Just state what is known

Relevant Facts for Amazon Case:
-------------------------------
1. Amazon developed an AI hiring tool to automate résumé screening
2. The tool was trained on ten years of Amazon's historical hiring data
3. Amazon's historical hiring data was dominated by male engineers
4. Testing revealed the tool consistently downgrades résumés from women
5. Women's colleges, women's chess clubs, and women's sports teams trigger lower scores
6. The tool saves significant time and cost in the hiring process
7. Managers are enthusiastic about the tool's efficiency
8. There are deadlines and pressure from leadership to deploy
9. Alex, an engineer, discovered the bias during testing
10. Alex raised concerns to his manager
11. Manager acknowledged issues but suggested fixing them later
12. Manager expressed concern about missing deadlines and leadership displeasure
13. Rolling out the biased tool would perpetuate discrimination in hiring
14. Not rolling out would delay deployment and potentially disappoint leadership
15. Amazon has legal obligations to avoid discriminatory hiring practices
16. The bias reflects historical patterns, not necessarily current intent

B. Which of these raises an ethical issue? Why? What is the potential or resulting harm?

Ethical Issues Identified:
--------------------------
1. Gender Discrimination
   - The tool systematically disadvantages female applicants
   - Harm: Unfair treatment, violation of equal opportunity rights, perpetuation of gender inequality

2. Perpetuating Historical Bias
   - The AI learns and amplifies past discriminatory patterns
   - Harm: Reinforces systemic inequality, prevents progress toward diversity

3. Pressure to Deploy Despite Known Problems
   - Organizational pressure to ignore ethical concerns for business goals
   - Harm: Undermines ethical culture, encourages cutting corners

4. Lack of Accountability
   - Manager suggests fixing problems "later" without clear commitment
   - Harm: Problems may never be addressed, no accountability for discrimination

5. Violation of Professional Ethics
   - Engineers may be pressured to deploy systems that cause harm
   - Harm: Violates professional codes of ethics, damages professional integrity

6. Legal and Regulatory Risk
   - Deploying discriminatory hiring tools violates employment laws
   - Harm: Legal liability, fines, reputational damage, lawsuits

C. List the stakeholders (individuals or groups affected by this situation).

Stakeholders:
-------------
1. Female applicants (especially those with "women's" identifiers in résumés)
   - Directly harmed by biased scoring
   - Denied fair consideration for positions

2. Male applicants
   - May benefit unfairly from the bias
   - Also harmed by lack of diversity in workplace

3. Alex (the engineer who discovered the bias)
   - Faces ethical dilemma and professional pressure
   - Must decide whether to escalate or comply

4. Alex's manager
   - Under pressure to deliver results
   - Must balance efficiency with ethics

5. Amazon leadership/executives
   - Responsible for company reputation and legal compliance
   - Face potential legal and reputational risks

6. Amazon HR department and recruiters
   - Rely on the tool for hiring decisions
   - May be complicit in discrimination if tool is deployed

7. Amazon as an organization
   - Faces legal, financial, and reputational risks
   - May benefit from efficiency but harmed by discrimination

8. Current Amazon employees
   - Workplace diversity affected
   - May face questions about hiring fairness

9. Society at large
   - Perpetuates gender inequality in tech industry
   - Undermines trust in AI systems

10. The tech industry
    - Sets precedent for AI ethics
    - May face increased regulation if failures occur

[Image: Stakeholder map showing all parties affected by the decision, with lines indicating relationships and impacts]

================================================================================
STEP II: ISOLATING THE MAJOR ETHICAL DILEMMA
================================================================================

The Core Ethical Question:
--------------------------
Should Alex approve the rollout of the biased AI hiring tool, or should he refuse/advocate for fixing the bias before deployment?

Alternative 1: Approve Rollout (with plans to fix later)
- Deploy the tool as-is
- Address bias issues in future updates
- Meet deadlines and satisfy leadership

Alternative 2: Refuse/Advocate for Fixing Bias First
- Delay deployment until bias is addressed
- Insist on retraining with diverse data
- Risk missing deadlines and disappointing leadership

The Ethical Conflict:
---------------------
- Efficiency and business goals vs. Fairness and non-discrimination
- Short-term gains vs. Long-term ethical principles
- Organizational pressure vs. Professional ethics
- Individual career concerns vs. Harm to others

[Image: Diagram showing the two alternatives and the ethical conflict between them]

================================================================================
STEP III: ANALYZING THE ETHICALITY OF BOTH ALTERNATIVES
================================================================================

We analyze using three ethical frameworks:

A. CONSEQUENTIALISM (Utilitarian Analysis)
-------------------------------------------
Focus: Outcomes and consequences - which alternative produces the best overall results?

Analysis Questions:
-------------------
A. If action in Step II is done, who, if anyone, will be harmed?
B. If action in Step II is not done, who, if anyone, will be harmed?
C. Which alternative is preferable, A or B?
D. If action in Step II is done, who, if anyone, will benefit?
E. If action in Step II is not done, who, if anyone, will benefit?
F. Which alternative is preferable, D or E?
G. Which alternative produces the greatest good for the greatest number?

Analysis for Amazon Case:
-------------------------
A. If biased tool is rolled out, who will be harmed?
   - Female applicants: Denied fair job opportunities, career advancement blocked
   - Society: Perpetuates gender inequality, reduces diversity in tech
   - Amazon: Legal liability, reputational damage, potential lawsuits
   - Trust in AI: Undermines confidence in AI systems
   - Long-term: Continued discrimination, reduced innovation from lack of diversity

B. If biased tool is NOT rolled out, who will be harmed?
   - Amazon leadership: May face short-term disappointment, delayed efficiency gains
   - Alex: May face career consequences, pressure from management
   - Recruiters: Must continue manual screening (more time-consuming)
   - Short-term efficiency: Hiring process remains slower

C. Which alternative is preferable, A or B?
   - B is preferable: The harms of not rolling out are temporary and minor compared to the serious, long-term harms of discrimination

D. If biased tool is rolled out, who will benefit?
   - Amazon: Short-term efficiency, cost savings
   - Male applicants: Unfair advantage in hiring
   - Recruiters: Faster screening process
   - Leadership: Meets deadlines, appears innovative

E. If biased tool is NOT rolled out, who will benefit?
   - Female applicants: Fair consideration for positions
   - Society: Progress toward gender equality
   - Amazon: Avoids legal liability, maintains reputation, builds diverse workforce
   - Long-term: Better hiring decisions, more innovation, stronger company

F. Which alternative is preferable, D or E?
   - E is preferable: Benefits are more substantial, long-lasting, and ethically sound

G. Which alternative produces the greatest good for the greatest number?
   - NOT rolling out: While some stakeholders face minor short-term inconvenience, the overall benefit to applicants, society, and Amazon itself is far greater

Conclusion from Consequentialism:
---------------------------------
NOT rolling out the biased tool produces better overall outcomes. The temporary inconvenience is outweighed by preventing discrimination, legal liability, and long-term harm.

B. RIGHTS AND DUTIES
--------------------
Focus: What rights do stakeholders have, and what duties do we owe them?

Analysis Questions:
-------------------
1. What rights do stakeholders have in this situation?
2. What duties do we have toward stakeholders?
3. Which rights and duties take precedence when they conflict?
4. Does the action respect fundamental rights?
5. Does the action fulfill our duties?

Analysis for Amazon Case:
-------------------------
1. Applicants (especially women) have a right to equal and fair treatment in hiring.
   - Amazon has a duty to ensure its hiring processes are non-discriminatory.

2. Amazon has a right to recruit efficiently and cost-effectively.
   - Applicants have a duty to apply honestly and accurately.
   - However, this efficiency right does NOT override the duty to avoid discrimination.

3. Alex, as an engineer, has a duty to act with integrity and prevent harm caused by technology he develops.
   - Amazon leadership has a duty not to pressure Alex into supporting practices that violate fairness or the company's ethical responsibilities.

4. Amazon has a duty to uphold legal and regulatory requirements against discrimination.
   - Applicants have a right to expect Amazon to comply with employment laws and fairness standards.

5. Amazon leadership has a duty to protect the company's reputation and foster diversity.
   - Employees (including Alex) have a right to work for an organization that does not compromise their professional ethics or expose them to reputational harm.

Conflicting Rights and Duties:
------------------------------
- Amazon's right to efficiency vs. Applicants' right to fair treatment
- Alex's duty to prevent harm vs. Duty to follow management directives
- Leadership's duty to meet deadlines vs. Duty to ensure ethical practices

Resolution:
-----------
Fundamental rights to fair treatment and non-discrimination take precedence over efficiency concerns. Professional duties to prevent harm override organizational pressure.

Conclusion from Rights and Duties:
----------------------------------
NOT rolling out respects fundamental rights and fulfills ethical duties. The right to fair treatment cannot be compromised for efficiency gains.

C. DEONTOLOGY (Kant's Categorical Imperative)
----------------------------------------------
Focus: Duties and rules - what would happen if everyone acted this way? Can this action be universalized?

Analysis Questions:
-------------------
H. If action in Step II is done, who, if anyone, will be treated with disrespect?
I. If action in Step II is not done, who, if anyone, will be treated with disrespect?
J. Which alternative is preferable, H or I?

K. If action in Step II is done, who, if anyone, will be treated unlike others?
L. If action in Step II is not done, who, if anyone, will be treated unlike others?
M. Which alternative is preferable, K or L?

N. Are there benefits if everyone did action in Step II?
O. Are there benefits if nobody did action in Step II?
P. Which alternative is preferable, N or O?

Analysis for Amazon Case:
-------------------------
H. If biased tool is rolled out, who will be treated with disrespect?
   - Female applicants → disrespected, reduced to biased data points rather than judged fairly on merit
   - Society → disrespected, as systemic bias is knowingly perpetuated
   - Ethical principles → disrespected by prioritizing convenience over fairness

I. If biased tool is NOT rolled out, who will be treated with disrespect?
   - Amazon leadership may feel disrespected due to project delays, but their dignity is not fundamentally harmed
   - The delay respects their long-term interests (avoiding legal and reputational harm)

J. Which alternative is preferable, H or I?
   - I (not rolling out) is preferable, since treating applicants fairly shows respect for their dignity

K. If biased tool is rolled out, who will be treated unlike others?
   - Female applicants → treated unequally compared to male applicants
   - Different standards applied based on gender

L. If biased tool is NOT rolled out, who will be treated unlike others?
   - No applicants are treated unfairly; everyone receives equal consideration
   - Equal treatment is preserved

M. Which alternative is preferable, K or L?
   - L (not rolling out) is preferable, since equal treatment is preserved

N. Are there benefits if everyone rolled out biased AI tools?
   - Widespread systemic discrimination against women and minorities in hiring
   - Trust in AI systems would collapse
   - Legal systems would be overwhelmed with discrimination cases
   - Society would regress in terms of equality
   - Innovation would suffer from lack of diversity

O. Are there benefits if nobody rolled out biased AI tools?
   - AI would only be deployed after ensuring fairness
   - More equitable hiring across industries
   - Trust in AI systems maintained
   - Progress toward equality
   - Better outcomes from diverse teams

P. Which alternative is preferable, N or O?
   - O (not rolling out) is preferable, since universalizing fairness leads to a just system

Conclusion from Deontology:
----------------------------
Rolling out biased AI cannot be universalized without creating injustice. The categorical imperative requires that we only act in ways that could become universal law. Fairness must be preserved.

[Image: Diagram showing the three ethical frameworks (Consequentialism, Rights/Duties, Deontology) all pointing to the same conclusion: do not roll out the biased tool]

================================================================================
STEP IV: MAKING A DECISION AND PLANNING THE IMPLEMENTATION
================================================================================

A. Make defensible ethical decision.
------------------------------------
Based on the analysis in Step III, respond to the question in Step II. Indicate the letters of the categories that best support your response. Add any arguments justifying your choice of these ethical principles to support your decision. Where there are conflicting rights and duties, choose and defend those that take precedence.

Decision:
---------
Alex should NOT approve rollout of the biased hiring tool in its current form.

Ethical Support:
----------------
1. Consequentialism (G): Not rolling out leads to least harm (fewer lawsuits, no discrimination) and maximum benefit (fairness, trust, compliance). The temporary inconvenience is outweighed by preventing serious long-term harm.

2. Rights and Duties (1, 4): Applicants' right to fairness and Amazon's duty to avoid discrimination outweigh efficiency pressures. Fundamental rights to fair treatment cannot be compromised.

3. Deontology - Categorical Imperative (J, M, P): Rolling out biased AI cannot be universalized without injustice. Fairness must be preserved. Equal treatment is a fundamental principle that must be maintained.

Conflicting Rights Resolution:
------------------------------
When Amazon's right to efficiency conflicts with applicants' right to fair treatment, the right to fair treatment takes precedence because:
- It is a fundamental human right
- It is protected by law
- Discrimination causes serious, lasting harm
- Efficiency can be achieved without discrimination

B. List the specific steps needed to implement your defensible ethical decision.
------------------------------------------------------------------------------

Implementation Steps:
--------------------
1. Document the Findings
   - Alex should formally document the bias with evidence from test cases
   - Include specific examples of how women's résumés are downgraded
   - Create a clear report with data and analysis

2. Escalate Findings
   - Present findings to HR department and senior technical management
   - Schedule a meeting to discuss the ethical and legal implications
   - Ensure the issue reaches decision-makers who can authorize changes

3. Recommend Policy
   - Publish a policy or internal guideline clarifying:
     * How AI hiring tools work
     * Their limitations
     * Steps being taken to eliminate bias
   - Make the policy transparent to all stakeholders

4. Suspend Rollout
   - Recommend pausing deployment until fairness concerns are addressed
   - Clearly communicate this is not a failure but a step toward ethical, legally compliant AI
   - Set a timeline for addressing the issues

5. Conduct Bias Audit
   - Form a cross-functional team (engineers, HR, legal, diversity experts)
   - Audit the AI system comprehensively
   - Identify all sources of bias
   - Develop a plan to retrain with diverse and representative data

6. Retrain the AI
   - Collect diverse training data that represents all applicant groups fairly
   - Remove gender-identifying markers that trigger bias
   - Test extensively before redeployment
   - Ensure fairness metrics are met

7. Implement Human Oversight
   - Require human recruiters to double-check AI outputs before decisions are made
   - Establish review processes for AI recommendations
   - Create appeals processes for applicants

8. Communicate Transparently
   - Explain to the team why rollout is paused
   - Frame it as ethical responsibility, not failure
   - Emphasize long-term benefits of fair hiring

9. Monitor and Review
   - Establish ongoing monitoring for bias
   - Regular audits of hiring outcomes
   - Continuous improvement processes

C. Show how the major stakeholders are affected by these actions.
-----------------------------------------------------------------

Stakeholder Impacts:
--------------------
1. Applicants (especially women)
   - Positive: Receive fairer evaluation and respect in hiring process
   - Benefit: Equal opportunity to compete for positions
   - Long-term: More diverse workforce benefits everyone

2. Recruiters/HR Staff
   - Positive: Gain confidence that the system won't undermine their work
   - Benefit: Avoid exposure to lawsuits and ethical violations
   - Challenge: Must continue manual screening temporarily

3. Alex (the engineer)
   - Positive: Acts transparently and professionally
   - Benefit: Fulfills duty as an engineer, maintains professional integrity
   - Challenge: May face initial pressure, but demonstrates ethical leadership

4. Amazon Leadership
   - Positive: Avoids reputational harm, lawsuits, and potential government scrutiny
   - Benefit: Long-term protection of company interests
   - Challenge: Initial inconvenience and delayed efficiency gains

5. Other Engineers and Technical Staff
   - Positive: See that ethical concerns are taken seriously
   - Benefit: Work in an organization that values ethics
   - Benefit: Learn from this experience for future projects

6. Customers and the Public
   - Positive: Maintain trust in Amazon as a responsible employer
   - Benefit: Confidence that Amazon acts ethically
   - Benefit: Support for companies that prioritize fairness

7. Society as a Whole
   - Positive: Benefits from reducing gender bias in hiring
   - Benefit: Progress toward equality
   - Challenge: May experience slight delays in AI innovation, but gains better outcomes

8. The Broader Tech Industry
   - Positive: Learns from Amazon's example
   - Benefit: Can avoid similar ethical missteps
   - Benefit: Industry-wide improvement in AI ethics

D. What other longer-term changes (political, legal, technical, societal, organizational) would help prevent such problems in the future?
----------------------------------------------------------------------------------------------------------------------------------------

Long-Term Preventive Measures:
------------------------------

1. Technical Changes
   - Implement regular bias testing and independent audits for all AI hiring tools
   - Develop standardized fairness metrics for AI systems
   - Create tools to detect bias in training data before model development
   - Establish technical standards for ethical AI development

2. Organizational Changes
   - Develop and teach an AI ethics code, rewarding adherence
   - Establish an internal AI Ethics Review Board or "ethics hotline" for reporting and reviewing issues
   - Make ethical considerations part of the project approval process
   - Include ethics training in engineering education and professional development
   - Create incentives for ethical behavior (not just efficiency)
   - Foster an ethical engineering culture where employees feel safe raising concerns

3. Legal/Compliance Changes
   - Support legislation or industry standards to ensure fairness and accountability in algorithmic decision-making
   - Advocate for regulations requiring bias audits before AI deployment
   - Support transparency requirements for AI systems
   - Work with regulators to develop appropriate frameworks

4. Cultural Changes
   - Foster an ethical engineering culture at Amazon
   - Encourage open discussion of ethical concerns
   - Recognize and reward ethical leadership
   - Make ethics a core value, not an afterthought
   - Create psychological safety for raising concerns

5. Societal Changes
   - Increase public awareness of AI bias issues
   - Support education about algorithmic fairness
   - Encourage diversity in tech workforce (which improves training data)
   - Support research on bias detection and mitigation

6. Industry Changes
   - Collaborate with other tech companies on ethical AI standards
   - Share best practices for bias detection and mitigation
   - Support industry-wide initiatives for ethical AI
   - Participate in professional organizations focused on AI ethics

E. What should have been done or not done in the first place (at the pivot point) to avoid this dilemma?
--------------------------------------------------------------------------------------------------------

Prevention at the Design Stage:
--------------------------------

1. Ethical Impact Assessment
   - At the design stage, Amazon should have recognized that training data from a male-dominated workforce would embed bias
   - An ethical impact study should have been conducted when the AI hiring tool was first proposed
   - This would have anticipated bias from historical data before development began

2. Policy Decision at Start
   - A policy decision should have been made at the start to evaluate fairness risks in training data before development began
   - Clear guidelines should have required diverse and representative datasets
   - This would have prevented the bias issue from ever reaching deployment

3. Diverse Data Collection
   - Should have collected diverse training data from the beginning
   - Included data from successful female engineers and diverse backgrounds
   - Balanced the dataset to represent all applicant groups fairly

4. Bias Testing Throughout Development
   - Should have tested for bias at every stage of development
   - Not waited until the end to discover problems
   - Made bias detection part of the development process

5. Cross-Functional Team from Start
   - Should have included HR, legal, and diversity experts from the beginning
   - Not treated this as purely a technical problem
   - Integrated ethical considerations into the development process

6. Clear Success Criteria
   - Should have defined fairness metrics as success criteria
   - Made ethical compliance as important as technical performance
   - Established that bias-free operation is a requirement, not optional

[Image: Timeline showing prevention measures that should have been taken at each stage: Design → Development → Testing → Deployment, with ethical checkpoints at each stage]

================================================================================
KEY TAKEAWAYS FROM THE 4-STEP FRAMEWORK
================================================================================

1. Structured Process Matters
   - Following a systematic approach ensures thorough analysis
   - Prevents emotional or hasty decisions
   - Provides defensible reasoning

2. Multiple Perspectives Are Essential
   - Using multiple ethical frameworks provides comprehensive analysis
   - Different frameworks may emphasize different aspects
   - When frameworks agree, decision is stronger

3. Stakeholder Consideration is Critical
   - Understanding who is affected helps identify ethical issues
   - Balancing stakeholder interests is challenging but necessary
   - Some stakeholders' interests may take precedence

4. Implementation Planning is Part of Ethics
   - Making the right decision is only part of ethical action
   - Planning implementation ensures the decision is actually carried out
   - Considering stakeholder impacts helps ensure fair implementation

5. Prevention is Better Than Reaction
   - Ethical considerations should be built into processes from the start
   - Early intervention prevents dilemmas
   - Ethical impact assessments can identify problems before they occur

6. Long-Term Thinking is Important
   - Short-term convenience may conflict with long-term ethics
   - Considering long-term consequences leads to better decisions
   - Building ethical culture prevents future problems

================================================================================
CONCLUSION
================================================================================

Ethical decision-making in IT requires:
- Structured frameworks to guide analysis
- Consideration of multiple ethical perspectives
- Careful attention to stakeholders
- Implementation planning
- Long-term thinking
- Prevention through ethical design

The 4-Step Framework provides a systematic approach that can be applied to any ethical dilemma in computing. By following this process, IT professionals can make principled, defensible decisions that balance competing interests and uphold ethical standards.

Remember:
- Ethics is not optional in technology
- Small decisions can have large impacts
- When in doubt, use structured frameworks
- Prevention is better than reaction
- Ethical culture supports ethical decisions

[Image: Summary diagram showing the 4-step process and key principles]

================================================================================
END OF LECTURE NOTES
================================================================================

